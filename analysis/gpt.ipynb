{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels:  [1 0 1 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Data Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Embedding\n",
    "def create_embeddings(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(texts)\n",
    "    return vectors\n",
    "\n",
    "# Clustering\n",
    "def perform_clustering(vectors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "    kmeans.fit(vectors)\n",
    "    return kmeans.labels_\n",
    "\n",
    "# Summarization\n",
    "def summarize_text(text):\n",
    "    model = Summarizer()\n",
    "    summary = model(text, min_length=60, max_length=150)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum euismod nulla nec magna dapibus, ac malesuada nibh rhoncus. Ut vel dictum quam, vitae congue velit. Etiam porttitor scelerisque lorem eu gravida. Quisque vitae enim velit. Donec commodo nunc ac ultrices gravida. Sed faucibus ultrices erat vel rutrum. Vivamus ornare magna vitae mauris venenatis, quis gravida justo viverra. Proin quis est odio. Sed vel felis non ipsum eleifend varius.\"\n",
    "\n",
    "texts = [preprocess_text(t) for t in text.split(\".\")]\n",
    "vectors = create_embeddings(texts)\n",
    "cluster_labels = perform_clustering(vectors, 2)\n",
    "\n",
    "print(\"Cluster Labels: \", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.265, 'neu': 0.241, 'pos': 0.494, 'compound': 0.4404}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from leia.leia import SentimentIntensityAnalyzer \n",
    "\n",
    "s = SentimentIntensityAnalyzer()\n",
    "\n",
    "# An√°lise de texto simples\n",
    "s.polarity_scores('Eu estou feliz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
